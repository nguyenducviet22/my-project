<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><entry><title type="html">How to use Keycloak Admin REST API</title><link rel="alternate" href="http://www.mastertheboss.com/keycloak/how-to-use-keycloak-admin-rest-api/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/keycloak/how-to-use-keycloak-admin-rest-api/</id><updated>2023-03-10T16:42:44Z</updated><content type="html">The Keycloak REST Admin API is a Web service Endpoint that allows you to manage Keycloak programmatically. It provides endpoints for creating, updating, and deleting Keycloak entities such as users, groups, clients, roles, and realms. You can use any programming language that supports HTTP requests to interact with the API. Pre-requisite: If you are new ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">What&amp;#8217;s new in Dashbuilder 0.27.0?</title><link rel="alternate" href="https://blog.kie.org/2023/03/whats-new-in-dashbuilder-0-27-0.html" /><author><name>William Siqueira</name></author><id>https://blog.kie.org/2023/03/whats-new-in-dashbuilder-0-27-0.html</id><updated>2023-03-10T11:40:46Z</updated><content type="html">was released yesterday (March 8th, 2023) and it comes with very interesting new features. Let’s explore the new release in this post! NEW SAMPLES SCREEN A new sample screen allows Dashbuilder to render dashboards from a remote or local repository. A sample is a dashboard that users can try without installing on their Dashbuilder. The samples’ screen can be accessed when no dashboard is available. You can see the samples’ screen in action in our , but soon you will hear about it because it will be part of . AUTOCOMPLETE AND SYNTAX CHECK Dashbuilder now supports autocomplete and syntax verification in and ! CONTROLLED CONCURRENT DATASET ACCESS Now dashbuilder unifies HTTP requests when multiple displayers try to access the same dataset. In practice if you have X displayers on a page, it used to result in X HTTP requests, now Dashbuilder makes a single request for all displayers. BUG FIXES Fixed navigation between dashboards: It is possible to have more than one dashboard on the same dashbuilder installation. The navigation between dashboards now refreshes the page, making it easier to navigate between dashboards; Dark mode in components: Victory Charts and Table external components now supports dark mode; Dark mode in VSCode: Dark mode is now fixed in VSCode extension CONCLUSION In this post we shared the new features and improvements in Dashbuilder 0.27.0! Stay tuned for more dashbuilder news. The post appeared first on .</content><dc:creator>William Siqueira</dc:creator></entry><entry><title>JBoss Tools for Eclipse 2023-03M3</title><link rel="alternate" type="text/html" href="https://tools.jboss.org/blog/4.27.0.am1.html" /><category term="release" /><category term="jbosstools" /><category term="jbosscentral" /><author><name>sbouchet</name></author><id>https://tools.jboss.org/blog/4.27.0.am1.html</id><updated>2023-03-11T12:06:25Z</updated><published>2023-03-10T00:00:00Z</published><content type="html">&lt;div&gt;&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Happy to announce 4.27.0.AM1 (Developer Milestone 1) build for Eclipse 2023-03M3.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Downloads available at &lt;a href="https://tools.jboss.org/downloads/jbosstools/2023-03/4.27.0.AM1.html"&gt;JBoss Tools 4.27.0 AM1&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-is-new"&gt;&lt;a class="anchor" href="#what-is-new"&gt;&lt;/a&gt;What is New?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Full info is at &lt;a href="https://tools.jboss.org/documentation/whatsnew/jbosstools/4.27.0.AM1.html"&gt;this page&lt;/a&gt;. Some highlights are below.&lt;/p&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="general"&gt;&lt;a class="anchor" href="#general"&gt;&lt;/a&gt;General&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="components-depreciation"&gt;&lt;a class="anchor" href="#components-depreciation"&gt;&lt;/a&gt;Components Depreciation&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;As previously announced &lt;a href="https://issues.redhat.com/browse/JBIDE-28678"&gt;here&lt;/a&gt;, we’re in the process to remove the Central / update tab from JBossTools in next release. This work can be followed &lt;a href="https://issues.redhat.com/browse/JBIDE-28852"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;That means that all the current extra features that can be installed via this tab needs to be available through a new channel. This channel already exists as p2 repo, but using &lt;a href="https://www.eclipse.org/mpc/"&gt;Eclipse Marketplace Client&lt;/a&gt; is more close to what’s existing right now.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Most of those additional features are already present in the &lt;a href="https://marketplace.eclipse.org/content/jboss-tools"&gt;Jboss marketplace entry&lt;/a&gt;, so it’s just a matter of use it to install your favorite feature.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="openshift"&gt;&lt;a class="anchor" href="#openshift"&gt;&lt;/a&gt;OpenShift&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="openshift-application-explorer-view-service-creation-support"&gt;&lt;a class="anchor" href="#openshift-application-explorer-view-service-creation-support"&gt;&lt;/a&gt;OpenShift Application Explorer view service creation support&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The missing create service feature that was available with odo 2.X is now back in this release.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;&lt;a href="https://tools.jboss.org/documentation/whatsnew/jbosstools/4.21.0.AM1.html#operator-based-services"&gt;See the previous annoucement&lt;/a&gt; on this feature&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect3"&gt; &lt;h4 id="openshift-application-explorer-view-service-binding-support"&gt;&lt;a class="anchor" href="#openshift-application-explorer-view-service-binding-support"&gt;&lt;/a&gt;OpenShift Application Explorer view service binding support&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Once you have created a service, you can link it to a component using a binding.&lt;/p&gt; &lt;/div&gt; &lt;div class="imageblock"&gt; &lt;div class="content"&gt; &lt;img src="https://tools.jboss.org/documentation/whatsnew/openshift/images/link-service.gif" alt="link service" width="80%" /&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="hibernate-tools"&gt;&lt;a class="anchor" href="#hibernate-tools"&gt;&lt;/a&gt;Hibernate Tools&lt;/h3&gt; &lt;div class="sect3"&gt; &lt;h4 id="runtime-provider-updates"&gt;&lt;a class="anchor" href="#runtime-provider-updates"&gt;&lt;/a&gt;Runtime Provider Updates&lt;/h4&gt; &lt;div class="paragraph"&gt; &lt;p&gt;A new Hibernate 6.2 runtime provider incorporates Hibernate Core version 6.2.0.CR2, Hibernate Ant version 6.2.0.CR2 and Hibernate Tools version 6.2.0.CR2.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 6.1 runtime provider now incorporates Hibernate Core version 6.1.7.Final, Hibernate Ant version 6.1.7.Final and Hibernate Tools version 6.1.7.Final.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The Hibernate 5.6 runtime provider now incorporates Hibernate Core version 5.6.15.Final and Hibernate Tools version 5.6.15.Final.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect2"&gt; &lt;h3 id="and-more"&gt;&lt;a class="anchor" href="#and-more"&gt;&lt;/a&gt;And more…​&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;You can find more noteworthy updates in on &lt;a href="https://tools.jboss.org/documentation/whatsnew/jbosstools/4.27.0.AM1.html"&gt;this page&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Enjoy!&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Stéphane Bouchet&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt;</content><summary>Happy to announce 4.27.0.AM1 (Developer Milestone 1) build for Eclipse 2023-03M3. Downloads available at JBoss Tools 4.27.0 AM1. What is New? Full info is at this page. Some highlights are below. General Components Depreciation As previously announced here, we’re in the process to remove the Central / update tab from JBossTools in next release. This work can be followed here. That means that all the current extra features that can be installed via this tab needs to be available through a new channel. This channel already exists as p2 repo, but using Eclipse Marketplace Client is more close to what’s existing right now. Most of those additional features...</summary><dc:creator>sbouchet</dc:creator><dc:date>2023-03-10T00:00:00Z</dc:date></entry><entry><title type="html">WildFly Maven Plugin</title><link rel="alternate" href="https://wildfly.org//news/2023/03/09/WildFly-Maven-Plugin/" /><author><name>James R. Perkins</name></author><id>https://wildfly.org//news/2023/03/09/WildFly-Maven-Plugin/</id><updated>2023-03-09T00:00:00Z</updated><content type="html">The has introduced a new dev goal. If you are familiar with the run goal, this goal is very similar. However, it watches for changes to source files. If changes are found, the WAR is rebuilt and redeployed. This new goal is available in version 4.1.0.Beta3 of the wildfly-maven-plugin. USING THE DEV GOAL In its simplest form you enable the plugin like any other maven plugin: &lt;plugin&gt; &lt;groupId&gt;org.wildfly.plugins&lt;/groupId&gt; &lt;artifactId&gt;wildfly-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${version.wildfly-maven-plugin}&lt;/version&gt; &lt;/plugin&gt; Once added to your POM you can simply execute mvn wildfly:dev on your project, and you should be up and running. With no configuration, a full server is provisioned in your projects build directory, e.g. target. Changes to source files are monitored. If required, the compile:compile goal will be invoked. If a resource needs to be copied, the resources:resources goal will be invoked. In some cases the deployment might also need to be redeployed. You can also configure the goal to provision a custom version of WildFly. Below is an example of configuring a cloud server with the cloud-server layer with an H2 database. &lt;plugin&gt; &lt;groupId&gt;org.wildfly.plugins&lt;/groupId&gt; &lt;artifactId&gt;wildfly-maven-plugin&lt;/artifactId&gt; &lt;version&gt;${version.wildfly-maven-plugin}&lt;/version&gt; &lt;configuration&gt; &lt;feature-packs&gt; &lt;feature-pack&gt; &lt;location&gt;org.wildfly:wildfly-galleon-pack:${version.server}&lt;/location&gt; &lt;/feature-pack&gt; &lt;feature-pack&gt; &lt;location&gt;org.wildfly.cloud:wildfly-cloud-galleon-pack:${version.cloud.fp}&lt;/location&gt; &lt;/feature-pack&gt; &lt;/feature-packs&gt; &lt;layers&gt; &lt;layer&gt;cloud-server&lt;/layer&gt; &lt;layer&gt;h2-driver&lt;/layer&gt; &lt;/layers&gt; &lt;/configuration&gt; &lt;/plugin&gt; Full documentation for the goal can be found in the . LIMITATIONS There are currently a couple limitations on this goal. The first is this goal will only work with WAR deployments. The other is changes to the POM file are not watched. If you change the POM you need to kill, CTRL+C, the job and restart the process. CONCLUSION Hopefully this goal is useful for more rapid development. If you’d like to see new features or have questions on how this new goal works, open a on GitHub or in the . If you find a bug feel free to report it in .</content><dc:creator>James R. Perkins</dc:creator></entry><entry><title type="html">Serverless Logic Web Tools support to OpenAPI and AsyncAPI specifications</title><link rel="alternate" href="https://blog.kie.org/2023/03/serverless-logic-web-tools-support-to-openapi-and-asyncapi-specifications.html" /><author><name>Saravana Balaji</name></author><id>https://blog.kie.org/2023/03/serverless-logic-web-tools-support-to-openapi-and-asyncapi-specifications.html</id><updated>2023-03-08T12:47:26Z</updated><content type="html">While editing Serverless Workflow files, you can register OpenAPI endpoints and AsyncAPI channels and pass them as functions. These functions will be available on the Serverless Workflow Editor’s Service Catalog Explorer. This article explains how one can link OpenAPI and AsyncAPI specifications and have their functions available through autocomplete. This feature is available both on Serverless Logic Web Tools and the VS Code extension. On Web tools, the API specifications can be linked via external registries. SERVICE CATALOG IN WEB TOOLS You can access the Serverless Logic Web Tools. Before creating a workflow, you must download and start the Extended Services. STARTING EXTENDED SERVICES Procedure: 1. In the Serverless Logic Web Tools web application, click on the cogwheel (⚙️) in the top-right corner and go to the “KIE Sandbox Extended Services” tab. 2. Select the “Click to setup” option. 3. Select your operating system from the dropdown. 4. Click on the “Download” option highlighted. 5. The kie_sandbox_extended_services_&lt;os&gt;_&lt;version&gt;.&lt;format&gt; file will be downloaded. Follow the instructions provided therein for moving the downloaded app. 6. Click the next button and follow the instructions provided there to open the application. Some of the features in Serverless Logic Web Tools require integration with Red Hat OpenShift Application and Data Services. Now, in the Red Hat OpenShift application and Data Services, let us create a service account. CREATING A SERVICE ACCOUNT You can create or use a service account from your Red Hat OpenShift Application and Data Services console and add the service account to the Serverless Logic Web Tools. Prerequisites * You have access to the Red Hat OpenShift Application and Data Services console. Procedure 1. To create a service account in Red Hat Openshift Application and Data Services, perform the following steps: 1. Go to. 2. Click “Create Service Account.” 3. Enter a service account name in the Short description field of the Create a Service Account window. 2. Click Create. 1. A modal displaying your client ID and client secret appears. 2. Copy and save the client ID and client secret. 3. Check that I have copied the client ID and secret checkboxes, and click Close. 3. If you already have a service account, find your client ID and client secret. 4. In the Serverless Logic Web Tools, click on the cogwheel (⚙️) in the top-right corner and go to the Service Account tab. 5. Enter your client ID and client secret in the respective fields. 6. Click Apply. 7. The content in the Service Account tab updates and displays Your Service Account information as a set message. CREATING A SERVICE REGISTRY You can create or use a Service Registry instance from your Red Hat OpenShift Application and Data Services console and add the Service Registry to Serverless Logic Web Tools. Prerequisites * You have access to the Red Hat OpenShift Application and Data Services console. * You have created a service account. Procedure: 1. To create a Service Registry instance in Red Hat Openshift Application and Data Services console, perform the following steps: 1. Go to the. 2. Click the “Create Service Registry Instance” button. 2. Enter a Service Registry instance name in the Create a Service Registry Instance window and click Create. 1. The list of Service Registry instances updates with your instance. 2. Find the Service Registry instance you created in the list and click on it. 3. Go to the Settings tab and click on “Grant access.” 4. In the drop-down, select the service account you created in the previous procedure. 5. Select a role for your service account. 6. Click Save. 7. Click on the menu in the top-right corner of the screen. 3. Click Connection. 1. A drawer opens, containing the required connection and authentication information. 2. Copy the value of the Core Registry API. 4. If you already have a Service Registry, find the value of the Core Registry API of your Service Registry. 5. In the Serverless Logic Web Tools web application, click on the cogwheel (⚙️) in the top-right corner and go to the Service Registry tab. 6. Enter a name for your registry. You can enter the same name that you used while creating the Service Registry instance. 7. Enter the value of the Core Registry API and click Apply. 8. The Service Registry tab’s content updates and displays your Service Registry information in a predefined message. UPLOAD THE API SPECIFICATION Once you have the Service account and Service registry created, you are set to upload the API specification file, which could be an OpenAPI or an AsyncAPI. Procedure: 1. On the OpenShift Application Console, go to the Service Registry instance that you created. 2. Click the Upload Artifact button, and a modal window opens. 3. On the modal, enter the group and artifacts ID, which are mandatory fields for usage in the Serverless Workflow Web Tools. 4. You can choose type from the dropdown menu, or you can leave the default option Auto-Detect alone. 5. In the artifact section, you can browse or drag and drop the API specification file, or you can also copy-paste the content directly into the text area. 6. Finally, click “upload.” ACCESSING THE SERVICE CATALOG ON WEB TOOLS When you have all the prerequisites ready, it is possible to create a workflow and try the Service Catalog feature. You can create a new workflow by clicking the JSON or YAML button on the home page. An untitled document will be opened. You can click on the Create a Serverless Workflow option to generate a basic template workflow. Just above the functions property, there will be an Add Function option. When you click that option, a side widget containing a list of function suggestions will appear. These functions are extracted from the API specification files that you uploaded on the Red Hat OpenShift Application Console. When you select a particular function, it will automatically generate auto-filled name, operation, and type properties. That is all for now, soon we will have an article demonstrating the Service Catalog in the Serverless Workflow Editor VS Code extension. Stay tuned! The post appeared first on .</content><dc:creator>Saravana Balaji</dc:creator></entry><entry><title>Our advice for configuring Knative Broker for Apache Kafka</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/03/08/configuring-knative-broker-apache-kafka" /><author><name>Matthias Wessendorf</name></author><id>04600ac2-35c4-4460-a212-3719a3c5c1e6</id><updated>2023-03-08T07:00:00Z</updated><published>2023-03-08T07:00:00Z</published><summary type="html">&lt;p&gt;In this article, you will learn how to set up the &lt;a href="https://knative.dev/docs/eventing/brokers/broker-types/kafka-broker/"&gt;Knative Broker implementation for Apache Kafka&lt;/a&gt; in a production environment. Recently, the Kafka implementation has been announced as &lt;a href="https://developers.redhat.com/articles/2022/11/15/knative-broker-enhances-kafka-openshift-serverless"&gt;General Availablitly&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;One common question for production systems is always the need for an optimal configuration based on the given environment. This article gives recommendations on how to pick a good default configuration for the Knative Broker implementation for Apache Kafka.&lt;/p&gt; &lt;p&gt;The article is based on a small yet production-ready setup of Apache Kafka and Apache Zookeeper, each system consisting of three nodes. You can find a reference Kafka configuration based on &lt;a href="https://strimzi.io/"&gt;Strimzi.io&lt;/a&gt; on the &lt;a href="https://github.com/strimzi/strimzi-kafka-operator/blob/0.32.0/examples/kafka/kafka-persistent.yaml"&gt;Strimzi GitHub page&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This article is not giving recommendations for the configuration of the Kubernetes cluster.&lt;/p&gt; &lt;h2&gt;Setting up the Knative Broker&lt;/h2&gt; &lt;p&gt;Each broker object uses a Kafka topic for the storage of incoming CloudEvents. The recommendation to start with is as follows:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Partitions: 10&lt;/li&gt; &lt;li&gt;Replication Factor: 3&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Taking this configuration gives you a fault-tolerant, highly-available, and yet scalable basis for your project. Topics are partitioned, meaning they are spread over a number of buckets located on different Kafka brokers. To make your data fault tolerant and highly available, every topic can be replicated, even across geo-regions or datacenters. You can find more detailed information in the &lt;a href="https://kafka.apache.org/intro"&gt;Apache Kafka documentation&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Configuration aspects such as topic partitions or replication factor directly relate to the actual sizing of the cluster. For instance, if your cluster consists of three nodes, you cannot set the replication factor to a higher number, as it directly relates to the available nodes of the Apache Kafkacluster. You can find details about implications in the &lt;a href="https://strimzi.io/documentation/"&gt;Strimzi documentation&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;An example Knative Broker configuration&lt;/h2&gt; &lt;p&gt;Let us take a look at a possible configuration of a Knative Broker for Apache Kafka with this defined cluster in mind:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;apiVersion: v1 kind: ConfigMap metadata: name: &lt;broker-name&gt;-config data: bootstrap.servers: &lt;url&gt; auth.secret.ref.name: &lt;optional-secret-name&gt; default.topic.partitions: "10" default.topic.replication.factor: "3" --- apiVersion: eventing.knative.dev/v1 kind: Broker metadata: annotations: eventing.knative.dev/broker.class: Kafka name: &lt;broker-name&gt; spec: config: apiVersion: v1 kind: ConfigMap name: &lt;broker-name&gt;-config delivery: retry: 12 backoffPolicy: exponential backoffDelay: PT0.5S deadLetterSink: ref: apiVersion: eventing.knative.dev/v1 kind: Broker name: &lt;dead-letter-sink-broker-name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We see two manifests defined:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;A &lt;code&gt;ConfigMap&lt;/code&gt; resource&lt;/li&gt; &lt;li&gt;A &lt;code&gt;Broker&lt;/code&gt; resource.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;The &lt;code&gt;ConfigMap&lt;/code&gt; defines the URL to the Apache Kafka cluster and references a secret for TLS/SASL &lt;a href="https://knative.dev/docs/eventing/brokers/broker-types/kafka-broker/#security"&gt;security support&lt;/a&gt;. The manifest also sets the partitions and replication factor for the Kafka topic, internally used for the &lt;code&gt;Broker&lt;/code&gt; object, to store incoming CloudEvents as Kafka records. The &lt;code&gt;Broker&lt;/code&gt; uses the &lt;code&gt;eventing.knative.dev/broker.class&lt;/code&gt; indicating the Kafka-based Knative Broker implementation should be used. On the &lt;code&gt;spec&lt;/code&gt;, it references the &lt;code&gt;ConfigMap&lt;/code&gt;, as well configuration on the broker's event delivery.&lt;/p&gt; &lt;h3&gt;Broker event delivery guarantees and retries&lt;/h3&gt; &lt;p&gt;Knative provides various configuration parameters to control the delivery of events in case of failure. This configuration is able to define a number of retry attempts, a backoff delay, and a backoff policy (linear or exponential). If the event delivery is not successful, the event is delivered to the dead letter sink, if present. The &lt;code&gt;delivery&lt;/code&gt; spec object is global for the given broker object and can be overridden on a per &lt;code&gt;Trigger &lt;/code&gt;basis, if needed.&lt;/p&gt; &lt;p&gt;The following resources offer more details on the &lt;code&gt;delivery&lt;/code&gt; spec:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://github.com/knative/specs/blob/main/specs/eventing/data-plane.md"&gt;Knative Eventing Data Plane Contract&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://knative.dev/docs/eventing/event-delivery/#configuring-broker-event-delivery"&gt;Broker event delivery&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;The Knative Broker as a dead letter sink approach&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;deadLetterSink&lt;/code&gt; object can be any &lt;a href="https://knative.dev/docs/concepts/duck-typing/#addressable"&gt;&lt;code&gt;Addressable&lt;/code&gt;&lt;/a&gt; object that conforms to the Knative Eventing sink contract, such as a Knative Service, a Kubernetes Service, or a URI. However, this example is configuring a &lt;code&gt;deadLetterSink&lt;/code&gt;, with the different broker object. The benefit of this highly recommended approach is that all undelivered messages are sent to a Knative broker object and consumed from there, using the standard Knative Broker and Trigger APIs.&lt;/p&gt; &lt;h2&gt;An example trigger configuration&lt;/h2&gt; &lt;p&gt;The triggers are used for the egress out of the broker to consuming services. Triggers are executed on the referenced broker object. The following is an example of a trigger configuration:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;apiVersion: eventing.knative.dev/v1 kind: Trigger metadata: name: &lt;trigger-name&gt; annotations: kafka.eventing.knative.dev/delivery.order: &lt;delivery-order&gt; spec: broker: &lt;broker-name&gt; filter: attributes: type: &lt;cloud-event-type&gt; &lt;ce-extension&gt;: &lt;ce-extension-value&gt; subscriber: ref: apiVersion: v1 kind: Service name: &lt;receiver-name&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We see a trigger configuration for a specific &lt;code&gt;broker&lt;/code&gt; object, which filters the available CloudEvents, their attributes, and custom CloudEvent extension attributes. Matching events are routed to the &lt;code&gt;subscriber&lt;/code&gt;, which can be any &lt;a href="https://knative.dev/docs/concepts/duck-typing/#addressable"&gt;&lt;code&gt;Addressable&lt;/code&gt;&lt;/a&gt; object that conforms to the Knative Eventing sink contract, as defined above.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; We recommend applying filters on triggers for CloudEvent attributes and extensions. If no &lt;code&gt;filter&lt;/code&gt; is provided, all occurring CloudEvents are routed to the referenced &lt;code&gt;subscriber&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Message delivery order&lt;/h3&gt; &lt;p&gt;When dispatching events to the &lt;code&gt;subscriber&lt;/code&gt;, the Knative Kafka Broker can be configured to support different delivery ordering guarantees by using the &lt;code&gt;kafka.eventing.knative.dev/delivery.order&lt;/code&gt; annotation on every &lt;code&gt;Trigger&lt;/code&gt; object.&lt;/p&gt; &lt;p&gt;The supported consumer delivery guarantees are:&lt;/p&gt; &lt;ul&gt;&lt;li dir="ltr"&gt;&lt;code&gt;unordered&lt;/code&gt;: An unordered consumer is a non-blocking consumer that delivers messages unordered while preserving proper offset management. This is useful when there is a high demand for parallel consumption and no need for explicit ordering. One example could be the processing of click analytics.&lt;/li&gt; &lt;li dir="ltr"&gt;&lt;code&gt;ordered&lt;/code&gt;: An ordered consumer is a per-partition blocking consumer that waits for a successful response from the CloudEvent subscriber before it delivers the next message of the partition. This is useful when there is a need for more strict ordering or if there is a relationship or grouping between events. One example could be the processing of customer orders.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The default ordering guarantee is &lt;code&gt;unordered&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Trigger delivery guarantees and retries&lt;/h3&gt; &lt;p&gt;The global broker delivery configuration can be overridden on a per-trigger basis using the &lt;code&gt;delivery&lt;/code&gt; on the &lt;code&gt;Trigger spec&lt;/code&gt;. The behavior is the same as defined for the Broker event delivery guarantees and retries.&lt;/p&gt; &lt;h2&gt;Our advice for Knative Broker configuration&lt;/h2&gt; &lt;p&gt;In this article, we demonstrated how to set up the &lt;a href="https://knative.dev/docs/eventing/brokers/broker-types/kafka-broker/"&gt;Knative Broker implementation for Apache Kafka&lt;/a&gt; in a production environment. We provided recommendations for picking a good default configuration for the Knative Broker implementation for Apache Kafka. Feel free to comment below if you have questions. We welcome your feedback.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/03/08/configuring-knative-broker-apache-kafka" title="Our advice for configuring Knative Broker for Apache Kafka"&gt;Our advice for configuring Knative Broker for Apache Kafka&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Matthias Wessendorf</dc:creator><dc:date>2023-03-08T07:00:00Z</dc:date></entry><entry><title>Quarkus 3.0.0.Alpha5 released - now with Hibernate ORM 6, new Dev UI and more!</title><link rel="alternate" href="&#xA;                https://quarkus.io/blog/quarkus-3-0-0-alpha5-released/&#xA;            " /><author><name>Max Rydahl Andersen (https://twitter.com/maxandersen)</name></author><id>https://quarkus.io/blog/quarkus-3-0-0-alpha5-released/</id><updated>2023-03-08T00:00:00Z</updated><published>2023-03-08T00:00:00Z</published><summary type="html">We are in the process of getting Quarkus 3 ready - with the last alpha, we got our main branch to Jakarta EE 10 to let us getting more things integrated and tested faster. This time we move from Hibernate 5 to Hibernate 6 - which will cause breakages thus...</summary><dc:creator>Max Rydahl Andersen (https://twitter.com/maxandersen)</dc:creator><dc:date>2023-03-08T00:00:00Z</dc:date></entry><entry><title>6-step tutorial on installing Ansible 2.3 on RHEL 9.1</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/03/07/install-ansible-23-on-rhel-91" /><author><name>Tathagata Paul</name></author><id>20d4294e-a08c-4f4b-a9c7-5c78ea545e9e</id><updated>2023-03-07T07:00:00Z</updated><published>2023-03-07T07:00:00Z</published><summary type="html">&lt;p&gt;The &lt;a href="https://developers.redhat.com/products/ansible/overview"&gt;Red Hat Ansible Automation Platform&lt;/a&gt; is an enterprise framework for sharing automation across your organization. This article will demonstrate how to install Ansible Automation Platform 2.3 on a machine running Red Hat Enterprise Linux 9.1.&lt;/p&gt; &lt;h2&gt;6 steps to install Ansible Automation Platform 2.3 on RHEL 9.1&lt;/h2&gt; &lt;p&gt;Follow these quick and easy steps to installation.&lt;/p&gt; &lt;h3&gt;1. Set up prerequisites&lt;/h3&gt; &lt;p&gt;Make sure you have the following prerequisites before starting the installation process:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Red Hat Ansible Automation Platform subscription&lt;/li&gt; &lt;li&gt;Minimum 4GB of RAM&lt;/li&gt; &lt;li&gt;Minimum of 2 CPUs&lt;/li&gt; &lt;li&gt;20GB of dedicated hard disk space&lt;/li&gt; &lt;/ol&gt;&lt;h3&gt;2. Download the Ansible Automation Platform&lt;/h3&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/products/ansible/download"&gt;Download&lt;/a&gt; the Ansible Automation Platform 2.3 and then extract the files. Figure 1 displays the download page.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/figure_1.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/figure_1.jpg?itok=UY6V_IRJ" width="1440" height="664" alt="Download page for Ansible Automation Platform" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: The Ansible Automation Platform software download page.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;You will see the following files in the extracted directory:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[user@user ~ ]$ ls bundle  collections  group_vars inventory  licenses  README.md  setup.sh&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Before attempting to the install Ansible Automation Platform, update all the system libraries by running the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;sudo dnf update -y  &amp;&amp; dnf upgrade -y&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;3. Configuring the Ansible inventory file&lt;/h3&gt; &lt;p&gt;Configure the credentials for Ansible and PostgreSQL in the Ansible inventory file. The inventory file also contains details about the database.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;[automationcontroller] fqdn ansible_connection=local [database] [all:vars] admin_password='redhat' pg_host='' pg_port='' pg_database='awx' pg_username='awx' pg_password='redhat'&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Update the fields according to the requirements. Then, we will be good to go with our installation.&lt;/p&gt; &lt;h3&gt;4. Running the setup script&lt;/h3&gt; &lt;p&gt;Run the setup.sh file in the extracted folder. There are also various installation scenarios listed &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_ansible_automation_platform/2.3/html/red_hat_ansible_automation_platform_installation_guide/assembly-platform-install-scenario"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;sudo ./setup.sh&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;5. Accessing the Ansible Automation Platform console&lt;/h3&gt; &lt;p&gt;After successfully installing the Ansible Automation Platform 2.3, access the Ansible Automation Platform console via the URL: - &lt;a href="https://localhost/"&gt;https://localhost/&lt;/a&gt;. Log in with the &lt;strong&gt;admin&lt;/strong&gt; username and password set in the inventory file, as shown in Figure 2.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/figure_2_0.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/figure_2_0.jpg?itok=xdgnbMcD" width="600" height="522" alt="Ansible Automation Platform Login Page" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 2: The Ansible Automation Platform login page.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;6. Create a subscription allocation&lt;/h3&gt; &lt;p&gt;Create a subscription allocation in the &lt;a href="https://access.redhat.com/management/subscription_allocations"&gt;Red Hat Customer Portal&lt;/a&gt; and export the manifest from the overview page. Upload the manifest to activate your subscription. You can also register for a trial subscription by clicking the &lt;strong&gt;Request Subscription&lt;/strong&gt; button shown in Figure 3.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/figure_3.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/figure_3.jpg?itok=KtziagcH" width="600" height="363" alt="Requesting a subscription for Ansible Automation Platform" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3: The Ansible Subscription page.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;You can explore more ways to import a subscription &lt;a href="https://docs.ansible.com/automation-controller/latest/html/userguide/import_license.html"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Figure 4 shows the Ansible Automation Platform web console.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/figure_4.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/figure_4.jpg?itok=Z1Up7Y8B" width="1440" height="685" alt="Ansible Automation Platform Web Console" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 4: The Ansible Automation Platform 2.3 web console.&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;What's next in your automation journey?&lt;/h2&gt; &lt;p&gt;You can get started with the Ansible Automation Platform by exploring &lt;a href="https://developers.redhat.com/products/ansible/getting-started"&gt;interactive labs at Red Hat Developer&lt;/a&gt;. Ansible Automation Platform is also available as a managed offering on &lt;a href="https://www.redhat.com/en/technologies/management/ansible/azure"&gt;Microsoft Azure&lt;/a&gt; and as a self-managed offering on &lt;a href="https://www.redhat.com/en/technologies/management/ansible/aws"&gt;Amazon Web Services&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/03/07/install-ansible-23-on-rhel-91" title="6-step tutorial on installing Ansible 2.3 on RHEL 9.1"&gt;6-step tutorial on installing Ansible 2.3 on RHEL 9.1&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Tathagata Paul</dc:creator><dc:date>2023-03-07T07:00:00Z</dc:date></entry><entry><title type="html">Openshift Cheatsheet for DevOps</title><link rel="alternate" href="http://www.mastertheboss.com/soa-cloud/openshift/openshift-cheatsheet/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/soa-cloud/openshift/openshift-cheatsheet/</id><updated>2023-03-06T14:05:59Z</updated><content type="html">In this article you will find a comprehensive Openshift Container Platform cheat sheet for System Administrators and Developers. Login and Configuration Firstly, let’s check the most common commands for Login and Configuration in OpenShift: #login with a user oc login https://192.168.99.100:8443 -u developer -p developer #login as system admin oc login -u system:admin #User Information ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>5 global environment variables provided by OpenShift GitOps</title><link rel="alternate" href="https://developers.redhat.com/articles/2023/03/06/5-global-environment-variables-provided-openshift-gitops" /><author><name>Gerald Nunn</name></author><id>c83046ef-a133-418c-81db-a3bdf883e8dc</id><updated>2023-03-06T07:00:00Z</updated><published>2023-03-06T07:00:00Z</published><summary type="html">&lt;p&gt;Red Hat OpenShift GitOps provides a compelling out-of-the-box experience for the majority of Red Hat OpenShift customers. However, there are times when organizations have specific requirements to satisfy that require additional tuning. OpenShift GitOps provides a number of global-level environment variables that organizations can apply to tailor their experience.&lt;/p&gt; &lt;h2&gt;5 Environment variables: Overview&lt;/h2&gt; &lt;p&gt;OpenShift GitOps supports the use of environment variables to control operator behavior in specific areas. The following table provides a brief overview of five variables from the &lt;a href="https://github.com/redhat-developer/gitops-operator/blob/master/docs/OpenShift%20GitOps%20Usage%20Guide.md#setting-environment-variables"&gt;&lt;u&gt;upstream documentation&lt;/u&gt;&lt;/a&gt;. Note that this list can change between releases, so it's always a good idea to verify new, deprecated, or removed variables.&lt;/p&gt; &lt;div&gt; &lt;table cellspacing="0" width="624"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;th&gt;&lt;strong&gt;Environment Variable&lt;/strong&gt;&lt;/th&gt; &lt;th&gt;&lt;strong&gt;Default&lt;/strong&gt;&lt;/th&gt; &lt;th&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/th&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;ARGOCD_CLUSTER_CONFIG_NAMESPACES&lt;/td&gt; &lt;td&gt;None&lt;/td&gt; &lt;td&gt;OpenShift GitOps instances in the identified namespaces are granted limited additional permissions to manage specific cluster-scoped resources, which include platform operators, optional OLM operators, user management, etc. &lt;p&gt;Multiple namespaces can be specified via a comma delimited list.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;CONTROLLER_CLUSTER_ROLE&lt;/td&gt; &lt;td&gt;None&lt;/td&gt; &lt;td&gt;This environment variable enables administrators to configure a common cluster role to use across all managed namespaces in the role bindings the operator creates for the Argo CD application controller.&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;DISABLE_DEFAULT_ARGOCD_CONSOLELINK&lt;/td&gt; &lt;td&gt;false&lt;/td&gt; &lt;td&gt;When set to `true`, this will disable the ConsoleLink for Argo CD, which appears in the OpenShift Console Application Launcher.&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;DISABLE_DEFAULT_ARGOCD_INSTANCE&lt;/td&gt; &lt;td&gt;false&lt;/td&gt; &lt;td&gt;When set to `true`, this will disable the default 'ready-to-use' installation of Argo CD in the `openshift-gitops` namespace.&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;SERVER_CLUSTER_ROLE&lt;/td&gt; &lt;td&gt;None&lt;/td&gt; &lt;td&gt;This environment variable enables Administrators to configure a common cluster role to use across all of the managed namespaces in the role bindings the operator creates for the Argo CD server.&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;The environment variables can be attached to the subscription object, automatically including them in the operator deployment managed by the subscription. Specifying environment variables in the subscription object is done by including them in spec.config.env as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;apiVersion: operators.coreos.com/v1alpha1 kind: Subscription metadata: name: openshift-gitops-operator namespace: openshift-operators spec: channel: gitops-1.7 config: env: - name: ARGOCD_CLUSTER_CONFIG_NAMESPACES value: openshift-gitops, gitops - name: CONTROLLER_CLUSTER_ROLE value: gitops-controller installPlanApproval: Automatic name: openshift-gitops-operator source: redhat-operators sourceNamespace: openshift-marketplace &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;5 Environment variables: Details&lt;/h2&gt; &lt;p&gt;The subsequent sections provide more details about the five environment variables.&lt;/p&gt; &lt;h3&gt;1. ARGOCD_CLUSTER_CONFIG_NAMESPACES&lt;/h3&gt; &lt;p&gt;In OpenShift GitOps, the operator can deploy Argo CD in one of two scopes: cluster or namespace. A cluster-scoped instance is intended to deploy and manage resources across a cluster, whereas namespace scope is limited to a set of specified namespaces. Most importantly, cluster scoped instances have access to cluster-level resources and thus are typically, but not always, used for cluster configuration.&lt;/p&gt; &lt;p&gt;In OpenShift GitOps, the default instance deployed in the openshift-gitops namespace is cluster scoped and, as mentioned previously, intended for cluster configuration. Any other instances deployed are namespace scoped by default and only have access to resources in the namespace to which they are deployed.&lt;/p&gt; &lt;p&gt;To prevent users from deploying Argo CD instances with cluster-level privileges, a cluster administrator must identify the namespaces with cluster privileges by using this environment variable in the subscription object. Since namespace administrators do not have access to the subscription object, this prevents them from elevating the privileges of their own instance and bypassing cluster security.&lt;/p&gt; &lt;p&gt;When an instance is designated as cluster scoped, the operator will automatically create a set of ClusterRole and ClusterRoleBindings for the application controller and server service accounts in that namespace. This default role is not intended to be the equivalent of the standard cluster-admin role. It is given a much smaller set of permissions as follows:&lt;/p&gt; &lt;div&gt; &lt;table cellspacing="0" width="NaN"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td width="NaN"&gt; &lt;p&gt;&lt;strong&gt;Resource (API Group)&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;&lt;strong&gt;What it Manages&lt;/strong&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td width="NaN"&gt; &lt;p&gt;operators.coreos.com, operator.openshift.io&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;Optional operators managed by OLM&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td width="NaN"&gt; &lt;p&gt;user.openshift.io , rbac.authorization.k8s.io&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;Groups, users, and their permissions.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td width="NaN"&gt; &lt;p&gt;config.openshift.io&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;Control plane Operators managed by CVO are used to configure cluster-wide build configuration, registry configuration, scheduler policies, etc.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td width="NaN"&gt; &lt;p&gt;storage.k8s.io&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;Storage.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td width="NaN"&gt; &lt;p&gt;console.openshift.io&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;Console customization.&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td width="NaN"&gt; &lt;p&gt;machine.openshift.io, machineconfiguration.openshift.io&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;Machine API (machines, MachineSets, machine configuration, etc.)&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td width="NaN"&gt; &lt;p&gt;compliance.openshift.io&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;Compliance operator, ScanSettingBinding only&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td width="NaN"&gt; &lt;p&gt;Other&lt;/p&gt; &lt;/td&gt; &lt;td width="NaN"&gt; &lt;p&gt;Namespaces, PV, PVC, and ConfigMaps&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt; &lt;p&gt; &lt;/p&gt; &lt;p&gt;These permissions can be extended by creating additional ClusterRole/ClusterRoleBinding as needed.&lt;/p&gt; &lt;h3&gt;2. CONTROLLER_CLUSTER_ROLE&lt;/h3&gt; &lt;p&gt;When OpenShift GitOps is deployed in namespace mode, it will create a set of roles and RoleBindings in every namespace that the instance manages to enable the application controller to deploy resources into those namespaces. The cluster administrator indicates these managed namespaces by labeling the namespace:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;argocd.argoproj.io/managed-by: &lt;namespace-of-target-gitops&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The roles that the operator in the namespace creates are namespace scoped and only have access to namespace resources. It cannot perform any actions outside of the namespaces it manages.&lt;/p&gt; &lt;p&gt;While the out-of-the-box role works well for many use cases, organizations may need to modify this role depending on their security requirements, additional resources they want to manage, etc. For example, an organization with security needs driven by regulatory requirements may wish to define a specific set of reduced permissions to meet those requirements.&lt;/p&gt; &lt;p&gt;This environment variable enables the cluster administrator to specify an alternate cluster role instead of the default operator-created role for the application controller. When this variable is provided, the operator will not create a default Role in the namespace but rather only create a RoleBinding in the namespace to the provided cluster role. It is up to the administrator to create this cluster role, having full control over the permissions.&lt;/p&gt; &lt;p&gt;One key aspect to note when defining your own role is that Argo CD will attempt to interact with all resources. When using this feature, you must either provide permission to view/get/watch all resources in your custom cluster role or configure the ArgoCD Custom Resource to include or exclude specific resources via resourceInclusions or resourceExclusions defined in the role.&lt;/p&gt; &lt;p&gt;As an example, in my own installations, I like to specify an alternate ClusterRole that has the following features:&lt;/p&gt; &lt;ul&gt;&lt;li aria-level="1"&gt;The Kubernetes ClusterRole &lt;a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/#aggregated-clusterroles"&gt;&lt;u&gt;aggregation&lt;/u&gt;&lt;/a&gt; feature allows the cluster role to be easily extended without directly modifying the role.&lt;/li&gt; &lt;li aria-level="1"&gt;The view all permissions role is aggregated into the above ClusterRole.&lt;/li&gt; &lt;li aria-level="1"&gt;The write permissions role incorporates the out-of-the-box admin ClusterRole that OpenShift uses for namespace administrators. The admin is a cluster aggregated role that components like OLM leverage so that when new operators are installed, their resources are automatically aggregated into the role.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Given all this, the following is an example of the role I used where the variable CONTROLLER_CLUSTER_ROLE is set to the gitops-controller ClusterRole.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-yaml"&gt;apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: annotations: rbac.authorization.kubernetes.io/autoupdate: "true" name: gitops-controller aggregationRule: clusterRoleSelectors: - matchLabels: gitops/aggregate-to-controller: "true" rules: [] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: gitops-controller-admin labels: gitops/aggregate-to-controller: "true" aggregationRule: clusterRoleSelectors: - matchLabels: rbac.authorization.k8s.io/aggregate-to-admin: "true" rules: [] --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: gitops-controller-view labels: gitops/aggregate-to-controller: "true" rules: - apiGroups: - '*' resources: - '*' verbs: - get - list - watch &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;3. DISABLE_DEFAULT_ARGOCD_CONSOLELINK&lt;/h3&gt; &lt;p&gt;By default, the operator will create a default instance in the openshift-gitops namespace and create a &lt;a href="https://docs.openshift.com/container-platform/4.9/web_console/customizing-the-web-console.html#creating-custom-links_customizing-web-console"&gt;Console Link&lt;/a&gt; to access this instance. This custom link is rendered in the OpenShift console under the &lt;strong&gt;Applications&lt;/strong&gt; menu, visible to all OpenShift users, as shown in Figure 1.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/openshift-console-link.jpg" data-featherlight="image"&gt;&lt;img loading="lazy" src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/openshift-console-link.jpg?itok=l15iKZNu" width="384" height="478" alt="A screenshot of the console link in the OpenSift applications menu." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt;&lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt;Figure 1. The console link in the OpenSift applications menu.&lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;However, this instance is typically used for cluster configuration, and we do not want tenants on the cluster to access this instance. While RBAC controls access to the instance, showing a link to users who cannot access it can be confusing.&lt;/p&gt; &lt;p&gt;Setting this variable to true will remove the ConsoleLink, and it will no longer appear in the console.&lt;/p&gt; &lt;h3&gt;4. DISABLE_DEFAULT_ARGOCD_INSTANCE&lt;/h3&gt; &lt;p&gt;As mentioned, the operator will create a cluster-scoped instance in the openshift-gitops namespace by default. Setting this environment variable to true will disable this behavior, and the default instance will not be created.&lt;/p&gt; &lt;p&gt;This can be useful when users do not require this instance (cluster configuration is managed remotely) or simply require a different namespace. An example of the latter could be users migrating from community Argo CD where the typical practice is to deploy in an argocd namespace.&lt;/p&gt; &lt;h3&gt;5. SERVER_CLUSTER_ROLE&lt;/h3&gt; &lt;p&gt;This environment variable is the equivalent of the previously discussed CONTROLLER_CLUSTER_ROLE except for the server component of Argo CD. It operates identically to that variable but binds the server service component to the specified ClusterRole.&lt;/p&gt; &lt;p&gt;In practice, there is typically much less need to customize or change this role than for the controller, but the option to do so is there.&lt;/p&gt; &lt;h2&gt;Customizing with environment variables&lt;/h2&gt; &lt;p&gt;This article described how to easily customize the behavior of the OpenShift GitOps operator using five environment variables in the &lt;strong&gt;Subscription&lt;/strong&gt; object. If you have questions, feel free to comment below. We welcome your feedback.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2023/03/06/5-global-environment-variables-provided-openshift-gitops" title="5 global environment variables provided by OpenShift GitOps"&gt;5 global environment variables provided by OpenShift GitOps&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Gerald Nunn</dc:creator><dc:date>2023-03-06T07:00:00Z</dc:date></entry></feed>
